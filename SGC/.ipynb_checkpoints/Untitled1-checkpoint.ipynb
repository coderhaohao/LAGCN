{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from utils import load_citation, sgc_precompute, set_seed\n",
    "from models import get_model\n",
    "from metrics import accuracy\n",
    "import pickle as pkl\n",
    "from args import get_citation_args\n",
    "from time import perf_counter\n",
    "\n",
    "# Arguments\n",
    "args = get_citation_args()\n",
    "\n",
    "if args.tuned:\n",
    "    if args.model == \"SGC\":\n",
    "        with open(\"{}-tuning/{}.txt\".format(args.model, args.dataset), 'rb') as f:\n",
    "            args.weight_decay = pkl.load(f)['weight_decay']\n",
    "            print(\"using tuned weight decay: {}\".format(args.weight_decay))\n",
    "    else:\n",
    "        raise NotImplemented\n",
    "\n",
    "# setting random seeds\n",
    "set_seed(args.seed, args.cuda)\n",
    "\n",
    "adj, features, labels, idx_train, idx_val, idx_test = load_citation(args.dataset, args.normalization, args.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2505.3396"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(adj.data.to_dense().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2708, 2708])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Module\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_regression(model,\n",
    "                     train_features, train_labels,\n",
    "                     val_features, val_labels,\n",
    "                     epochs=args.epochs, weight_decay=args.weight_decay,\n",
    "                     lr=args.lr, dropout=args.dropout):\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr,\n",
    "                           weight_decay=weight_decay)\n",
    "    t = perf_counter()\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(train_features)\n",
    "        loss_train = F.cross_entropy(output, train_labels)\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        output = model(val_features)\n",
    "        acc_val = accuracy(output, val_labels)\n",
    "        print(acc_val)\n",
    "    train_time = perf_counter()-t\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        output = model(val_features)\n",
    "        acc_val = accuracy(output, val_labels)\n",
    "\n",
    "    return model, acc_val, train_time\n",
    "\n",
    "def test_regression(model, test_features, test_labels):\n",
    "    model.eval()\n",
    "    return accuracy(model(test_features), test_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGC(nn.Module):\n",
    "    \"\"\"\n",
    "    A Simple PyTorch Implementation of Logistic Regression.\n",
    "    Assuming the features have been preprocessed with k-step graph propagation.\n",
    "    \"\"\"\n",
    "    def __init__(self, nfeat, nclass):\n",
    "        super(SGC, self).__init__()\n",
    "\n",
    "        self.W = nn.Linear(nfeat, nclass)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.W(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_bak = features.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SGC(features.size(1),labels.max().item()+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = feature_bak.clone()\n",
    "t_feature = features.clone()\n",
    "feature_list = [t_feature.clone()]\n",
    "t = perf_counter()\n",
    "for i in range(degree):\n",
    "    t_feature = torch.spmm(adj, t_feature)\n",
    "    feature_list.append(t_feature.clone())\n",
    "precompute_time = perf_counter()-t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.6624, 0.4388, 0.4472, 0.3927, 0.5865, 0.2698, 0.6745]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.ws_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGC_WEIGHT_SUM(nn.Module):\n",
    "    def __init__(self, fea_size, label_size, emb_size, degree_size, fwd_num, drop_rate):\n",
    "        super(SGC_WEIGHT_SUM, self).__init__()\n",
    "        self.trans_lin = nn.Linear(fea_size, emb_size)\n",
    "        init.xavier_uniform_(self.trans_lin.weight)\n",
    "#         self.ws_lin = nn.Linear(degree_size,1)\n",
    "# #         init.xavier_normal_(self.ws_lin.weight)\n",
    "#         self.ws_lin.weight = torch.nn.Parameter(\n",
    "#             torch.FloatTensor(np.random.normal(loc=0.5, scale=0.1, size=(1,degree_size))))\n",
    "        self.ws_weight = nn.Parameter(\n",
    "            torch.FloatTensor(np.random.normal(loc=0.5, scale=0.1, size=(1,degree_size))))\n",
    "        self.fwd_lin = []\n",
    "        # Previous Forward Layer\n",
    "        for i in range(fwd_num-1):\n",
    "            lin_mod = nn.Linear(emb_size, emb_size)\n",
    "            init.xavier_uniform_(lin_mod.weight)\n",
    "            self.fwd_lin.append(lin_mod)\n",
    "            self.fwd_lin.append(nn.Sigmoid())\n",
    "        # Final Forward Layer\n",
    "        lin_mod = nn.Linear(emb_size, label_size)\n",
    "        init.xavier_uniform_(lin_mod.weight)\n",
    "        self.fwd_lin.append(lin_mod)\n",
    "        self.fwd_lin = nn.Sequential(*self.fwd_lin)\n",
    "        print(self.fwd_lin)\n",
    "        self.drop = nn.Dropout(drop_rate)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         self.ws_lin.weight = torch.nn.Parameter(torch.FloatTensor([[1]]))\n",
    "#         for p in self.ws_lin.parameters():\n",
    "#             p.requires_grad=False\n",
    "\n",
    "    def forward(self, x, istrain=False):\n",
    "        trans_emb = self.trans_lin(x.permute([0,2,1])).permute([0,2,1])\n",
    "#         ws_emb = torch.squeeze(F.linear(trans_emb,F.softmax(self.ws_weight, dim=1)), dim=-1)\n",
    "        ws_emb = torch.squeeze(F.linear(trans_emb,self.ws_weight, dim=1), dim=-1)\n",
    "#         ws_emb = torch.squeeze(self.ws_lin(trans_emb), dim=-1)\n",
    "        if istrain:\n",
    "            ws_emb = self.drop(ws_emb)\n",
    "        y_pred = self.fwd_lin(ws_emb)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (1): Sigmoid()\n",
      "  (2): Linear(in_features=128, out_features=7, bias=True)\n",
      ")\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() should return None, not 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-e0abade99f38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mset_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGC_WEIGHT_SUM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfea_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfwd_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() should return None, not 'tuple'"
     ]
    }
   ],
   "source": [
    "set_seed(1, args.cuda)\n",
    "model = SGC_WEIGHT_SUM(fea_size, label_size, emb_size, degree_size, fwd_num, drop_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_size = 1433\n",
    "label_size = 7\n",
    "emb_size = 128\n",
    "degree_size = 7\n",
    "fwd_num = 2\n",
    "drop_rate = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = feature_bak.clone()\n",
    "t_feature = features.clone()\n",
    "feature_list = [t_feature.clone()]\n",
    "t = perf_counter()\n",
    "for i in range(degree):\n",
    "    t_feature = torch.spmm(adj, t_feature)\n",
    "    feature_list.append(t_feature.clone())\n",
    "precompute_time = perf_counter()-t\n",
    "feature_list = [torch.unsqueeze(_, dim=-1) for _ in feature_list][0:degree_size]\n",
    "features = torch.cat(feature_list, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (1): Sigmoid()\n",
      "  (2): Linear(in_features=128, out_features=7, bias=True)\n",
      ")\n",
      "weight\n",
      "tensor([[0.1671, 0.1336, 0.1348, 0.1276, 0.1549, 0.1129, 0.1691]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "train begin\n",
      "[0.16711536, 0.13362992, 0.13475154, 0.1276067, 0.15490168, 0.112854116, 0.16914071]\n",
      "epoch 0, tr: 14.29, va: 31.60, ts:31.90\n",
      "epoch 1, tr: 14.29, va: 31.60, ts:31.90\n",
      "epoch 2, tr: 14.29, va: 31.60, ts:31.90\n",
      "epoch 3, tr: 14.29, va: 31.60, ts:31.90\n",
      "epoch 4, tr: 14.29, va: 31.60, ts:31.90\n",
      "epoch 5, tr: 14.29, va: 31.60, ts:31.90\n",
      "epoch 6, tr: 14.29, va: 31.60, ts:31.90\n",
      "epoch 7, tr: 14.29, va: 31.60, ts:31.90\n",
      "epoch 8, tr: 14.29, va: 31.60, ts:31.90\n",
      "epoch 9, tr: 14.29, va: 31.60, ts:31.90\n",
      "[0.16757868, 0.13491923, 0.13596313, 0.12697417, 0.15404887, 0.112270914, 0.16824496]\n",
      "epoch 10, tr: 14.29, va: 31.60, ts:31.90\n",
      "epoch 11, tr: 14.29, va: 31.60, ts:31.90\n",
      "epoch 12, tr: 14.29, va: 31.60, ts:31.90\n",
      "epoch 13, tr: 14.29, va: 31.60, ts:31.90\n",
      "epoch 14, tr: 15.71, va: 31.40, ts:32.20\n",
      "epoch 15, tr: 35.71, va: 29.80, ts:29.50\n",
      "epoch 16, tr: 29.29, va: 19.80, ts:19.20\n",
      "epoch 17, tr: 30.71, va: 19.20, ts:17.10\n",
      "epoch 18, tr: 35.71, va: 26.20, ts:26.80\n",
      "epoch 19, tr: 15.00, va: 12.40, ts:13.10\n",
      "[0.1695699, 0.13656484, 0.13760789, 0.12578309, 0.1525979, 0.11121512, 0.16666123]\n",
      "epoch 20, tr: 14.29, va: 12.20, ts:13.00\n",
      "epoch 21, tr: 14.29, va: 12.20, ts:13.00\n",
      "epoch 22, tr: 14.29, va: 12.20, ts:13.00\n",
      "epoch 23, tr: 14.29, va: 12.20, ts:13.00\n",
      "epoch 24, tr: 20.00, va: 14.20, ts:13.80\n",
      "epoch 25, tr: 28.57, va: 20.80, ts:21.50\n",
      "epoch 26, tr: 22.86, va: 15.80, ts:14.10\n",
      "epoch 27, tr: 15.00, va: 11.60, ts:10.60\n",
      "epoch 28, tr: 15.00, va: 11.40, ts:10.40\n",
      "epoch 29, tr: 15.00, va: 11.40, ts:10.40\n",
      "[0.17189191, 0.1384367, 0.1394726, 0.1244133, 0.15093575, 0.11000385, 0.16484582]\n",
      "epoch 30, tr: 15.00, va: 11.40, ts:10.40\n",
      "epoch 31, tr: 15.00, va: 11.40, ts:10.40\n",
      "epoch 32, tr: 15.00, va: 11.40, ts:10.40\n",
      "epoch 33, tr: 15.00, va: 11.40, ts:10.40\n",
      "epoch 34, tr: 15.00, va: 11.40, ts:10.40\n",
      "epoch 35, tr: 15.71, va: 11.40, ts:10.40\n",
      "epoch 36, tr: 18.57, va: 11.60, ts:10.70\n",
      "epoch 37, tr: 23.57, va: 11.80, ts:11.50\n",
      "epoch 38, tr: 27.86, va: 12.40, ts:12.40\n",
      "epoch 39, tr: 36.43, va: 15.80, ts:16.50\n",
      "[0.17449227, 0.14051941, 0.1415334, 0.122886054, 0.14908661, 0.108655915, 0.16282627]\n",
      "epoch 40, tr: 52.14, va: 26.40, ts:24.30\n",
      "epoch 41, tr: 67.14, va: 38.00, ts:35.20\n",
      "epoch 42, tr: 76.43, va: 45.40, ts:44.20\n",
      "epoch 43, tr: 84.29, va: 53.20, ts:51.10\n",
      "epoch 44, tr: 87.14, va: 59.60, ts:56.40\n",
      "epoch 45, tr: 93.57, va: 63.20, ts:63.50\n",
      "epoch 46, tr: 97.14, va: 70.60, ts:70.30\n",
      "epoch 47, tr: 99.29, va: 73.60, ts:75.00\n",
      "epoch 48, tr: 98.57, va: 77.40, ts:79.40\n",
      "epoch 49, tr: 97.86, va: 78.40, ts:81.50\n",
      "[0.17735718, 0.14280722, 0.14368933, 0.12122798, 0.14708298, 0.107195884, 0.16063945]\n",
      "epoch 50, tr: 97.14, va: 78.00, ts:80.50\n",
      "epoch 51, tr: 95.00, va: 76.00, ts:79.70\n",
      "epoch 52, tr: 93.57, va: 74.80, ts:78.00\n",
      "epoch 53, tr: 92.14, va: 73.80, ts:76.10\n",
      "epoch 54, tr: 91.43, va: 72.80, ts:74.90\n",
      "epoch 55, tr: 92.14, va: 71.60, ts:74.30\n",
      "epoch 56, tr: 92.86, va: 72.60, ts:74.80\n",
      "epoch 57, tr: 92.86, va: 74.80, ts:75.60\n",
      "epoch 58, tr: 94.29, va: 75.40, ts:77.40\n",
      "epoch 59, tr: 96.43, va: 76.00, ts:78.00\n",
      "[0.18054369, 0.14534727, 0.14557347, 0.11949818, 0.14499618, 0.10567653, 0.15836465]\n",
      "epoch 60, tr: 97.14, va: 77.60, ts:79.30\n",
      "epoch 61, tr: 97.14, va: 78.20, ts:80.30\n",
      "epoch 62, tr: 97.86, va: 79.00, ts:81.60\n",
      "epoch 63, tr: 98.57, va: 79.00, ts:81.60\n",
      "epoch 64, tr: 98.57, va: 79.40, ts:82.10\n",
      "epoch 65, tr: 99.29, va: 79.20, ts:81.50\n",
      "epoch 66, tr: 99.29, va: 79.00, ts:81.20\n",
      "epoch 67, tr: 99.29, va: 79.00, ts:80.30\n",
      "epoch 68, tr: 99.29, va: 78.40, ts:79.30\n",
      "epoch 69, tr: 99.29, va: 78.00, ts:79.00\n",
      "[0.18430832, 0.14834331, 0.14588962, 0.11788546, 0.14305538, 0.10426519, 0.15625279]\n",
      "epoch 70, tr: 99.29, va: 78.00, ts:78.40\n",
      "epoch 71, tr: 99.29, va: 77.60, ts:77.70\n",
      "epoch 72, tr: 99.29, va: 77.00, ts:77.80\n",
      "epoch 73, tr: 99.29, va: 77.20, ts:77.60\n",
      "epoch 74, tr: 99.29, va: 77.00, ts:77.40\n",
      "epoch 75, tr: 99.29, va: 77.20, ts:77.60\n",
      "epoch 76, tr: 99.29, va: 77.40, ts:77.90\n",
      "epoch 77, tr: 99.29, va: 77.40, ts:77.90\n",
      "epoch 78, tr: 99.29, va: 77.00, ts:77.90\n",
      "epoch 79, tr: 99.29, va: 77.20, ts:78.00\n",
      "[0.1887, 0.15182689, 0.14436601, 0.116432205, 0.14131303, 0.10300024, 0.15436164]\n",
      "epoch 80, tr: 99.29, va: 77.20, ts:77.80\n",
      "epoch 81, tr: 99.29, va: 77.40, ts:77.80\n",
      "epoch 82, tr: 99.29, va: 77.20, ts:77.70\n",
      "epoch 83, tr: 99.29, va: 77.40, ts:78.10\n",
      "epoch 84, tr: 98.57, va: 77.60, ts:78.50\n",
      "epoch 85, tr: 98.57, va: 77.80, ts:78.40\n",
      "epoch 86, tr: 98.57, va: 78.00, ts:78.60\n",
      "epoch 87, tr: 98.57, va: 78.00, ts:78.80\n",
      "epoch 88, tr: 98.57, va: 78.00, ts:78.90\n",
      "epoch 89, tr: 98.57, va: 78.00, ts:78.80\n",
      "[0.19341405, 0.15553814, 0.14233072, 0.11496441, 0.13955973, 0.10172941, 0.15246348]\n",
      "epoch 90, tr: 98.57, va: 78.20, ts:79.00\n",
      "epoch 91, tr: 98.57, va: 77.80, ts:78.80\n",
      "epoch 92, tr: 98.57, va: 77.80, ts:79.00\n",
      "epoch 93, tr: 98.57, va: 78.00, ts:78.70\n",
      "epoch 94, tr: 98.57, va: 78.00, ts:78.70\n",
      "epoch 95, tr: 98.57, va: 78.20, ts:78.50\n",
      "epoch 96, tr: 98.57, va: 78.40, ts:78.30\n",
      "epoch 97, tr: 98.57, va: 78.00, ts:78.30\n",
      "epoch 98, tr: 98.57, va: 78.00, ts:78.30\n",
      "epoch 99, tr: 98.57, va: 78.00, ts:78.30\n",
      "max test acc criterion 82.1000\n",
      "[64.         98.57142857 79.4        82.1       ]\n",
      "max val acc criterion 82.1000\n",
      "[64.         98.57142857 79.4        82.1       ]\n",
      "Validation Accuracy: 78.0000 Test Accuracy: 0.7830\n",
      "Pre-compute time: 0.0802s, train time: 11.5271s, total: 11.6073s\n"
     ]
    }
   ],
   "source": [
    "set_seed(1, args.cuda)\n",
    "model = SGC_WEIGHT_SUM(fea_size, label_size, emb_size, degree_size, fwd_num, drop_rate)\n",
    "print('weight')\n",
    "print(F.softmax(model.ws_weight, dim=1))\n",
    "print('train begin')\n",
    "model, acc_val, train_time, score_array, ws_array = train_regression(\n",
    "    model, features[idx_train], labels[idx_train], features[idx_val], labels[idx_val],\n",
    "                 100, args.weight_decay, 1e-3, args.dropout, features[idx_test], labels[idx_test])\n",
    "acc_test = test_regression(model, features[idx_test], labels[idx_test])\n",
    "\n",
    "print(\"Validation Accuracy: {:.4f} Test Accuracy: {:.4f}\".format(acc_val, acc_test))\n",
    "print(\"Pre-compute time: {:.4f}s, train time: {:.4f}s, total: {:.4f}s\".format(precompute_time, train_time, precompute_time+train_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1bcafc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(ws_array.shape[1]):\n",
    "    plt.plot(ws_array[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a4134d7b8>"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a43a72d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(score_array[:,0],score_array[:,1],label='Train')\n",
    "plt.plot(score_array[:,0],score_array[:,2],label='Val')\n",
    "plt.plot(score_array[:,0],score_array[:,3],label='Test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[2,2], [2,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (1): Sigmoid()\n",
      "  (2): Linear(in_features=128, out_features=7, bias=True)\n",
      ")\n",
      "weight\n",
      "tensor([[0.1671, 0.1336, 0.1348, 0.1276, 0.1549, 0.1129, 0.1691]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "train begin\n",
      "epoch 0(0 W), tr: 14.29, va: 31.60, ts:31.90\n",
      "epoch 0(1 W), tr: 14.29, va: 31.60, ts:31.90\n",
      "epoch 0(2 W), tr: 14.29, va: 31.60, ts:31.90\n",
      "epoch 0(3 W), tr: 14.29, va: 31.60, ts:31.90\n",
      "epoch 0(4 W), tr: 14.29, va: 31.60, ts:31.90\n",
      "epoch 0(5 W), tr: 14.29, va: 31.60, ts:31.90\n",
      "epoch 0(6 W), tr: 14.29, va: 31.60, ts:31.90\n",
      "epoch 0(7 W), tr: 14.29, va: 31.60, ts:31.90\n",
      "epoch 0(8 W), tr: 14.29, va: 31.60, ts:31.90\n",
      "epoch 0(9 W), tr: 14.29, va: 31.60, ts:31.90\n",
      "epoch 0(10 W), tr: 14.29, va: 31.60, ts:31.90\n",
      "epoch 0(11 W), tr: 14.29, va: 31.60, ts:31.90\n",
      "epoch 0(12 W), tr: 14.29, va: 31.60, ts:31.90\n",
      "epoch 0(13 W), tr: 14.29, va: 31.60, ts:31.90\n",
      "epoch 0(14 W), tr: 14.29, va: 31.60, ts:31.90\n",
      "epoch 0(15 W), tr: 14.29, va: 31.60, ts:32.00\n",
      "epoch 0(16 W), tr: 22.14, va: 32.80, ts:33.70\n",
      "epoch 0(17 W), tr: 38.57, va: 29.20, ts:29.10\n",
      "epoch 0(18 W), tr: 30.00, va: 19.00, ts:17.30\n",
      "epoch 0(19 W), tr: 38.57, va: 23.20, ts:21.30\n",
      "epoch 0(20 W), tr: 35.00, va: 24.00, ts:24.60\n",
      "epoch 0(21 W), tr: 17.86, va: 12.60, ts:13.20\n",
      "epoch 0(22 W), tr: 14.29, va: 12.20, ts:13.00\n",
      "epoch 0(23 W), tr: 14.29, va: 12.20, ts:13.00\n",
      "epoch 0(24 W), tr: 15.00, va: 12.20, ts:13.10\n",
      "epoch 0(25 W), tr: 15.00, va: 12.20, ts:13.20\n",
      "epoch 0(26 W), tr: 15.71, va: 12.20, ts:13.30\n",
      "epoch 0(27 W), tr: 23.57, va: 15.20, ts:15.10\n",
      "epoch 0(28 W), tr: 30.00, va: 21.00, ts:21.90\n",
      "epoch 0(29 W), tr: 26.43, va: 16.40, ts:16.20\n",
      "epoch 0(0 A), tr: 26.43, va: 16.40, ts:16.20\n",
      "[0.16900519, 0.13514052, 0.13626836, 0.12649581, 0.15355228, 0.111871004, 0.16766696]\n",
      "epoch 0(1 A), tr: 26.43, va: 16.40, ts:16.20\n",
      "[0.17090127, 0.13665593, 0.13778278, 0.12538235, 0.1522005, 0.11088627, 0.1661909]\n",
      "epoch 0(2 A), tr: 26.43, va: 16.40, ts:16.20\n",
      "[0.17280528, 0.1381771, 0.13928574, 0.12426778, 0.15084815, 0.10990128, 0.16471468]\n",
      "epoch 0(3 A), tr: 26.43, va: 16.40, ts:16.20\n",
      "[0.17471948, 0.13970557, 0.1407655, 0.12315371, 0.14949739, 0.10891766, 0.1632407]\n",
      "epoch 0(4 A), tr: 26.43, va: 16.40, ts:16.20\n",
      "[0.17664722, 0.14124365, 0.14220609, 0.122042336, 0.14815104, 0.107937545, 0.1617722]\n",
      "epoch 0(5 A), tr: 26.43, va: 16.40, ts:16.20\n",
      "[0.17859313, 0.14279474, 0.14358555, 0.120936595, 0.14681284, 0.106963694, 0.16031337]\n",
      "epoch 0(6 A), tr: 26.43, va: 16.40, ts:16.20\n",
      "[0.18056381, 0.14436378, 0.14487466, 0.11984047, 0.1454878, 0.10599978, 0.15886973]\n",
      "epoch 0(7 A), tr: 26.43, va: 16.40, ts:16.20\n",
      "[0.18256772, 0.14595714, 0.1460361, 0.118758865, 0.14418195, 0.10505028, 0.15744802]\n",
      "epoch 0(8 A), tr: 26.43, va: 16.40, ts:16.20\n",
      "[0.18461509, 0.1475826, 0.14702651, 0.11769738, 0.14290226, 0.104120284, 0.15605588]\n",
      "epoch 0(9 A), tr: 26.43, va: 16.40, ts:16.20\n",
      "[0.1867167, 0.14924839, 0.14780246, 0.11666148, 0.14165546, 0.103214726, 0.15470076]\n",
      "epoch 1(0 W), tr: 20.00, va: 12.40, ts:11.50\n",
      "epoch 1(1 W), tr: 15.00, va: 11.40, ts:10.50\n",
      "epoch 1(2 W), tr: 15.00, va: 11.40, ts:10.40\n",
      "epoch 1(3 W), tr: 15.00, va: 11.40, ts:10.40\n",
      "epoch 1(4 W), tr: 15.00, va: 11.40, ts:10.40\n",
      "epoch 1(5 W), tr: 15.00, va: 11.40, ts:10.40\n",
      "epoch 1(6 W), tr: 15.00, va: 11.60, ts:10.40\n",
      "epoch 1(7 W), tr: 17.86, va: 11.60, ts:10.40\n",
      "epoch 1(8 W), tr: 20.00, va: 11.60, ts:10.90\n",
      "epoch 1(9 W), tr: 22.14, va: 11.80, ts:11.50\n",
      "epoch 1(10 W), tr: 25.71, va: 12.20, ts:12.50\n",
      "epoch 1(11 W), tr: 33.57, va: 14.20, ts:14.90\n",
      "epoch 1(12 W), tr: 42.14, va: 18.40, ts:19.60\n",
      "epoch 1(13 W), tr: 55.71, va: 29.20, ts:26.10\n",
      "epoch 1(14 W), tr: 70.71, va: 36.60, ts:34.40\n",
      "epoch 1(15 W), tr: 77.86, va: 45.80, ts:43.40\n",
      "epoch 1(16 W), tr: 82.86, va: 50.60, ts:49.30\n",
      "epoch 1(17 W), tr: 87.14, va: 54.80, ts:53.40\n",
      "epoch 1(18 W), tr: 88.57, va: 58.80, ts:57.10\n",
      "epoch 1(19 W), tr: 94.29, va: 61.60, ts:62.40\n",
      "epoch 1(20 W), tr: 96.43, va: 67.80, ts:67.70\n",
      "epoch 1(21 W), tr: 98.57, va: 71.80, ts:72.80\n",
      "epoch 1(22 W), tr: 99.29, va: 74.40, ts:76.80\n",
      "epoch 1(23 W), tr: 98.57, va: 76.80, ts:79.10\n",
      "epoch 1(24 W), tr: 97.86, va: 79.20, ts:79.70\n",
      "epoch 1(25 W), tr: 97.86, va: 78.60, ts:80.80\n",
      "epoch 1(26 W), tr: 97.14, va: 78.80, ts:80.00\n",
      "epoch 1(27 W), tr: 97.14, va: 78.40, ts:79.60\n",
      "epoch 1(28 W), tr: 96.43, va: 78.20, ts:79.70\n",
      "epoch 1(29 W), tr: 96.43, va: 78.00, ts:79.20\n",
      "epoch 1(0 A), tr: 96.43, va: 78.00, ts:79.20\n",
      "[0.1887596, 0.15092711, 0.14775716, 0.11584483, 0.14064491, 0.102476045, 0.15359035]\n",
      "epoch 1(1 A), tr: 96.43, va: 78.20, ts:79.20\n",
      "[0.19095296, 0.15272062, 0.14737669, 0.11504196, 0.139654, 0.10175181, 0.15250197]\n",
      "epoch 1(2 A), tr: 96.43, va: 78.20, ts:79.20\n",
      "[0.1932847, 0.15461789, 0.14679368, 0.11422767, 0.13865253, 0.101020284, 0.15140322]\n",
      "epoch 1(3 A), tr: 96.43, va: 78.40, ts:79.20\n",
      "[0.19573367, 0.15660267, 0.14606975, 0.11339675, 0.1376338, 0.10027663, 0.15028682]\n",
      "epoch 1(4 A), tr: 96.43, va: 78.40, ts:79.30\n",
      "[0.19828176, 0.15866084, 0.14523976, 0.1125487, 0.13659692, 0.0995202, 0.14915182]\n",
      "epoch 1(5 A), tr: 96.43, va: 78.20, ts:79.10\n",
      "[0.20091477, 0.1607811, 0.14432558, 0.11168448, 0.1355429, 0.09875177, 0.14799933]\n",
      "epoch 1(6 A), tr: 96.43, va: 78.20, ts:79.10\n",
      "[0.20362145, 0.1629542, 0.143342, 0.11080545, 0.13447328, 0.09797249, 0.14683111]\n",
      "epoch 1(7 A), tr: 96.43, va: 78.20, ts:79.10\n",
      "[0.20639284, 0.16517246, 0.14229953, 0.10991298, 0.1333897, 0.09718357, 0.14564893]\n",
      "epoch 1(8 A), tr: 96.43, va: 78.20, ts:79.10\n",
      "[0.20922169, 0.16742948, 0.14120603, 0.10900835, 0.13229369, 0.096386164, 0.14445455]\n",
      "epoch 1(9 A), tr: 96.43, va: 78.20, ts:79.10\n",
      "[0.21210217, 0.1697197, 0.1400676, 0.10809279, 0.13118671, 0.095581375, 0.14324965]\n",
      "epoch 2(0 W), tr: 96.43, va: 78.00, ts:79.40\n",
      "epoch 2(1 W), tr: 97.86, va: 78.60, ts:79.80\n",
      "epoch 2(2 W), tr: 97.86, va: 78.80, ts:79.90\n",
      "epoch 2(3 W), tr: 97.86, va: 79.00, ts:80.30\n",
      "epoch 2(4 W), tr: 97.86, va: 79.20, ts:80.20\n",
      "epoch 2(5 W), tr: 97.86, va: 78.80, ts:79.70\n",
      "epoch 2(6 W), tr: 98.57, va: 78.80, ts:80.70\n",
      "epoch 2(7 W), tr: 98.57, va: 78.40, ts:80.80\n",
      "epoch 2(8 W), tr: 99.29, va: 78.60, ts:80.40\n",
      "epoch 2(9 W), tr: 99.29, va: 78.40, ts:80.60\n",
      "epoch 2(10 W), tr: 99.29, va: 78.80, ts:80.90\n",
      "epoch 2(11 W), tr: 99.29, va: 78.40, ts:81.00\n",
      "epoch 2(12 W), tr: 99.29, va: 77.60, ts:80.80\n",
      "epoch 2(13 W), tr: 99.29, va: 78.00, ts:80.70\n",
      "epoch 2(14 W), tr: 99.29, va: 77.60, ts:80.10\n",
      "epoch 2(15 W), tr: 99.29, va: 77.60, ts:79.70\n",
      "epoch 2(16 W), tr: 99.29, va: 77.60, ts:79.50\n",
      "epoch 2(17 W), tr: 99.29, va: 77.60, ts:79.40\n",
      "epoch 2(18 W), tr: 99.29, va: 77.20, ts:79.20\n",
      "epoch 2(19 W), tr: 99.29, va: 77.20, ts:79.10\n",
      "epoch 2(20 W), tr: 99.29, va: 77.00, ts:78.70\n",
      "epoch 2(21 W), tr: 99.29, va: 77.00, ts:77.90\n",
      "epoch 2(22 W), tr: 99.29, va: 76.80, ts:77.80\n",
      "epoch 2(23 W), tr: 99.29, va: 76.20, ts:77.90\n",
      "epoch 2(24 W), tr: 99.29, va: 76.20, ts:77.70\n",
      "epoch 2(25 W), tr: 99.29, va: 76.40, ts:77.70\n",
      "epoch 2(26 W), tr: 99.29, va: 76.00, ts:77.30\n",
      "epoch 2(27 W), tr: 99.29, va: 76.20, ts:77.10\n",
      "epoch 2(28 W), tr: 99.29, va: 76.20, ts:76.90\n",
      "epoch 2(29 W), tr: 99.29, va: 76.20, ts:76.90\n",
      "epoch 2(0 A), tr: 99.29, va: 76.20, ts:76.90\n",
      "[0.21491197, 0.1720106, 0.1390703, 0.107174195, 0.13006045, 0.09475842, 0.142014]\n",
      "epoch 2(1 A), tr: 99.29, va: 76.20, ts:76.60\n",
      "[0.21779883, 0.17436782, 0.1380191, 0.10623595, 0.12890983, 0.09391739, 0.14075103]\n",
      "epoch 2(2 A), tr: 99.29, va: 76.40, ts:76.70\n",
      "[0.2207798, 0.17679365, 0.13690469, 0.105273746, 0.12773195, 0.09305691, 0.13945933]\n",
      "epoch 2(3 A), tr: 99.29, va: 76.20, ts:76.70\n",
      "[0.22385108, 0.17928103, 0.13573208, 0.10428839, 0.12652828, 0.092178255, 0.13814093]\n",
      "epoch 2(4 A), tr: 99.29, va: 76.00, ts:76.70\n",
      "[0.2270043, 0.18182102, 0.134508, 0.10328218, 0.1253018, 0.09128359, 0.13679914]\n",
      "epoch 2(5 A), tr: 99.29, va: 76.00, ts:76.60\n",
      "[0.23023048, 0.1844045, 0.13323879, 0.10225779, 0.12405558, 0.09037527, 0.13543749]\n",
      "epoch 2(6 A), tr: 99.29, va: 75.80, ts:76.60\n",
      "[0.23352134, 0.18702282, 0.1319302, 0.10121782, 0.122792825, 0.08945555, 0.13405943]\n",
      "epoch 2(7 A), tr: 99.29, va: 75.60, ts:76.40\n",
      "[0.23686941, 0.18966763, 0.13058718, 0.100164704, 0.12151641, 0.08852658, 0.13266805]\n",
      "epoch 2(8 A), tr: 99.29, va: 75.40, ts:76.10\n",
      "[0.24026832, 0.19233112, 0.1292142, 0.0991007, 0.120229006, 0.08759028, 0.13126633]\n",
      "epoch 2(9 A), tr: 99.29, va: 75.20, ts:76.20\n",
      "[0.24371257, 0.19500583, 0.12781523, 0.0980279, 0.11893311, 0.08664847, 0.12985694]\n",
      "[[ 0.          0.          0.         14.28571429 31.6        31.9       ]\n",
      " [ 0.          0.          1.         14.28571429 31.6        31.9       ]\n",
      " [ 0.          0.          2.         14.28571429 31.6        31.9       ]\n",
      " [ 0.          0.          3.         14.28571429 31.6        31.9       ]\n",
      " [ 0.          0.          4.         14.28571429 31.6        31.9       ]\n",
      " [ 0.          0.          5.         14.28571429 31.6        31.9       ]\n",
      " [ 0.          0.          6.         14.28571429 31.6        31.9       ]\n",
      " [ 0.          0.          7.         14.28571429 31.6        31.9       ]\n",
      " [ 0.          0.          8.         14.28571429 31.6        31.9       ]\n",
      " [ 0.          0.          9.         14.28571429 31.6        31.9       ]\n",
      " [ 0.          0.         10.         14.28571429 31.6        31.9       ]\n",
      " [ 0.          0.         11.         14.28571429 31.6        31.9       ]\n",
      " [ 0.          0.         12.         14.28571429 31.6        31.9       ]\n",
      " [ 0.          0.         13.         14.28571429 31.6        31.9       ]\n",
      " [ 0.          0.         14.         14.28571429 31.6        31.9       ]\n",
      " [ 0.          0.         15.         14.28571429 31.6        32.        ]\n",
      " [ 0.          0.         16.         22.14285714 32.8        33.7       ]\n",
      " [ 0.          0.         17.         38.57142857 29.2        29.1       ]\n",
      " [ 0.          0.         18.         30.         19.         17.3       ]\n",
      " [ 0.          0.         19.         38.57142857 23.2        21.3       ]\n",
      " [ 0.          0.         20.         35.         24.         24.6       ]\n",
      " [ 0.          0.         21.         17.85714286 12.6        13.2       ]\n",
      " [ 0.          0.         22.         14.28571429 12.2        13.        ]\n",
      " [ 0.          0.         23.         14.28571429 12.2        13.        ]\n",
      " [ 0.          0.         24.         15.         12.2        13.1       ]\n",
      " [ 0.          0.         25.         15.         12.2        13.2       ]\n",
      " [ 0.          0.         26.         15.71428571 12.2        13.3       ]\n",
      " [ 0.          0.         27.         23.57142857 15.2        15.1       ]\n",
      " [ 0.          0.         28.         30.         21.         21.9       ]\n",
      " [ 0.          0.         29.         26.42857143 16.4        16.2       ]\n",
      " [ 1.          0.          0.         26.42857143 16.4        16.2       ]\n",
      " [ 1.          0.          1.         26.42857143 16.4        16.2       ]\n",
      " [ 1.          0.          2.         26.42857143 16.4        16.2       ]\n",
      " [ 1.          0.          3.         26.42857143 16.4        16.2       ]\n",
      " [ 1.          0.          4.         26.42857143 16.4        16.2       ]\n",
      " [ 1.          0.          5.         26.42857143 16.4        16.2       ]\n",
      " [ 1.          0.          6.         26.42857143 16.4        16.2       ]\n",
      " [ 1.          0.          7.         26.42857143 16.4        16.2       ]\n",
      " [ 1.          0.          8.         26.42857143 16.4        16.2       ]\n",
      " [ 1.          0.          9.         26.42857143 16.4        16.2       ]\n",
      " [ 0.          1.          0.         20.         12.4        11.5       ]\n",
      " [ 0.          1.          1.         15.         11.4        10.5       ]\n",
      " [ 0.          1.          2.         15.         11.4        10.4       ]\n",
      " [ 0.          1.          3.         15.         11.4        10.4       ]\n",
      " [ 0.          1.          4.         15.         11.4        10.4       ]\n",
      " [ 0.          1.          5.         15.         11.4        10.4       ]\n",
      " [ 0.          1.          6.         15.         11.6        10.4       ]\n",
      " [ 0.          1.          7.         17.85714286 11.6        10.4       ]\n",
      " [ 0.          1.          8.         20.         11.6        10.9       ]\n",
      " [ 0.          1.          9.         22.14285714 11.8        11.5       ]\n",
      " [ 0.          1.         10.         25.71428571 12.2        12.5       ]\n",
      " [ 0.          1.         11.         33.57142857 14.2        14.9       ]\n",
      " [ 0.          1.         12.         42.14285714 18.4        19.6       ]\n",
      " [ 0.          1.         13.         55.71428571 29.2        26.1       ]\n",
      " [ 0.          1.         14.         70.71428571 36.6        34.4       ]\n",
      " [ 0.          1.         15.         77.85714286 45.8        43.4       ]\n",
      " [ 0.          1.         16.         82.85714286 50.6        49.3       ]\n",
      " [ 0.          1.         17.         87.14285714 54.8        53.4       ]\n",
      " [ 0.          1.         18.         88.57142857 58.8        57.1       ]\n",
      " [ 0.          1.         19.         94.28571429 61.6        62.4       ]\n",
      " [ 0.          1.         20.         96.42857143 67.8        67.7       ]\n",
      " [ 0.          1.         21.         98.57142857 71.8        72.8       ]\n",
      " [ 0.          1.         22.         99.28571429 74.4        76.8       ]\n",
      " [ 0.          1.         23.         98.57142857 76.8        79.1       ]\n",
      " [ 0.          1.         24.         97.85714286 79.2        79.7       ]\n",
      " [ 0.          1.         25.         97.85714286 78.6        80.8       ]\n",
      " [ 0.          1.         26.         97.14285714 78.8        80.        ]\n",
      " [ 0.          1.         27.         97.14285714 78.4        79.6       ]\n",
      " [ 0.          1.         28.         96.42857143 78.2        79.7       ]\n",
      " [ 0.          1.         29.         96.42857143 78.         79.2       ]\n",
      " [ 1.          1.          0.         96.42857143 78.         79.2       ]\n",
      " [ 1.          1.          1.         96.42857143 78.2        79.2       ]\n",
      " [ 1.          1.          2.         96.42857143 78.2        79.2       ]\n",
      " [ 1.          1.          3.         96.42857143 78.4        79.2       ]\n",
      " [ 1.          1.          4.         96.42857143 78.4        79.3       ]\n",
      " [ 1.          1.          5.         96.42857143 78.2        79.1       ]\n",
      " [ 1.          1.          6.         96.42857143 78.2        79.1       ]\n",
      " [ 1.          1.          7.         96.42857143 78.2        79.1       ]\n",
      " [ 1.          1.          8.         96.42857143 78.2        79.1       ]\n",
      " [ 1.          1.          9.         96.42857143 78.2        79.1       ]\n",
      " [ 0.          2.          0.         96.42857143 78.         79.4       ]\n",
      " [ 0.          2.          1.         97.85714286 78.6        79.8       ]\n",
      " [ 0.          2.          2.         97.85714286 78.8        79.9       ]\n",
      " [ 0.          2.          3.         97.85714286 79.         80.3       ]\n",
      " [ 0.          2.          4.         97.85714286 79.2        80.2       ]\n",
      " [ 0.          2.          5.         97.85714286 78.8        79.7       ]\n",
      " [ 0.          2.          6.         98.57142857 78.8        80.7       ]\n",
      " [ 0.          2.          7.         98.57142857 78.4        80.8       ]\n",
      " [ 0.          2.          8.         99.28571429 78.6        80.4       ]\n",
      " [ 0.          2.          9.         99.28571429 78.4        80.6       ]\n",
      " [ 0.          2.         10.         99.28571429 78.8        80.9       ]\n",
      " [ 0.          2.         11.         99.28571429 78.4        81.        ]\n",
      " [ 0.          2.         12.         99.28571429 77.6        80.8       ]\n",
      " [ 0.          2.         13.         99.28571429 78.         80.7       ]\n",
      " [ 0.          2.         14.         99.28571429 77.6        80.1       ]\n",
      " [ 0.          2.         15.         99.28571429 77.6        79.7       ]\n",
      " [ 0.          2.         16.         99.28571429 77.6        79.5       ]\n",
      " [ 0.          2.         17.         99.28571429 77.6        79.4       ]\n",
      " [ 0.          2.         18.         99.28571429 77.2        79.2       ]\n",
      " [ 0.          2.         19.         99.28571429 77.2        79.1       ]\n",
      " [ 0.          2.         20.         99.28571429 77.         78.7       ]\n",
      " [ 0.          2.         21.         99.28571429 77.         77.9       ]\n",
      " [ 0.          2.         22.         99.28571429 76.8        77.8       ]\n",
      " [ 0.          2.         23.         99.28571429 76.2        77.9       ]\n",
      " [ 0.          2.         24.         99.28571429 76.2        77.7       ]\n",
      " [ 0.          2.         25.         99.28571429 76.4        77.7       ]\n",
      " [ 0.          2.         26.         99.28571429 76.         77.3       ]\n",
      " [ 0.          2.         27.         99.28571429 76.2        77.1       ]\n",
      " [ 0.          2.         28.         99.28571429 76.2        76.9       ]\n",
      " [ 0.          2.         29.         99.28571429 76.2        76.9       ]\n",
      " [ 1.          2.          0.         99.28571429 76.2        76.9       ]\n",
      " [ 1.          2.          1.         99.28571429 76.2        76.6       ]\n",
      " [ 1.          2.          2.         99.28571429 76.4        76.7       ]\n",
      " [ 1.          2.          3.         99.28571429 76.2        76.7       ]\n",
      " [ 1.          2.          4.         99.28571429 76.         76.7       ]\n",
      " [ 1.          2.          5.         99.28571429 76.         76.6       ]\n",
      " [ 1.          2.          6.         99.28571429 75.8        76.6       ]\n",
      " [ 1.          2.          7.         99.28571429 75.6        76.4       ]\n",
      " [ 1.          2.          8.         99.28571429 75.4        76.1       ]\n",
      " [ 1.          2.          9.         99.28571429 75.2        76.2       ]]\n",
      "max test acc criterion 79.7000\n",
      "[ 0.          1.         24.         97.85714286 79.2        79.7       ]\n",
      "max val acc criterion 76.8000\n",
      "[ 0.          1.         22.         99.28571429 74.4        76.8       ]\n",
      "Validation Accuracy: 75.2000 Test Accuracy: 0.7620\n",
      "Pre-compute time: 0.0802s, train time: 15.9985s, total: 16.0787s\n"
     ]
    }
   ],
   "source": [
    "set_seed(1, args.cuda)\n",
    "model = SGC_WEIGHT_SUM(fea_size, label_size, emb_size, degree_size, fwd_num, drop_rate)\n",
    "print('weight')\n",
    "print(F.softmax(model.ws_weight, dim=1))\n",
    "print('train begin')\n",
    "model, acc_val, train_time, score_array, ws_array = bilevel_train_regression(\n",
    "    model, features[idx_train], labels[idx_train], features[idx_val], labels[idx_val],\n",
    "    3, 30, 10, args.weight_decay, 1e-3, args.dropout, features[idx_test], labels[idx_test])\n",
    "acc_test = test_regression(model, features[idx_test], labels[idx_test])\n",
    "\n",
    "print(\"Validation Accuracy: {:.4f} Test Accuracy: {:.4f}\".format(acc_val, acc_test))\n",
    "print(\"Pre-compute time: {:.4f}s, train time: {:.4f}s, total: {:.4f}s\".format(precompute_time, train_time, precompute_time+train_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0489, -0.0043,  0.0321,  ...,  0.0375, -0.0486, -0.0380],\n",
       "        [-0.0242, -0.0522, -0.0222,  ...,  0.0077,  0.0218,  0.0305],\n",
       "        [-0.0130, -0.0573,  0.0467,  ...,  0.0028, -0.0610, -0.0104],\n",
       "        ...,\n",
       "        [-0.0243, -0.0453,  0.0009,  ...,  0.0228, -0.0588, -0.0360],\n",
       "        [-0.0386,  0.0366, -0.0145,  ...,  0.0033,  0.0097,  0.0121],\n",
       "        [-0.0115, -0.0285, -0.0427,  ...,  0.0315,  0.0588, -0.0240]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.trans_lin.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bilevel_train_regression(model,\n",
    "                     train_features, train_labels,\n",
    "                     val_features, val_labels,\n",
    "                     total_epochs, w_batchs, a_batchs, weight_decay,\n",
    "                     lr, dropout, test_features, test_labels):\n",
    "\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=lr,\n",
    "#                            weight_decay=weight_decay)\n",
    "\n",
    "    w_parameters = [model.trans_lin.weight]\n",
    "    for i,lin in enumerate(model.fwd_lin):\n",
    "        if i %2 ==1:\n",
    "            continue\n",
    "        w_parameters.append(lin.weight)\n",
    "    alpha_parameters = [model.ws_weight]\n",
    "    opt_w = optim.Adam(w_parameters, lr=lr,\n",
    "                           weight_decay=weight_decay)\n",
    "    opt_a = optim.Adam(alpha_parameters, lr=lr*10,\n",
    "                           weight_decay=weight_decay)\n",
    "    \n",
    "    \n",
    "    t = perf_counter()\n",
    "    score_list = []\n",
    "    ws_list = []\n",
    "    w_index = 0\n",
    "    a_index = 0\n",
    "    for epoch in range(total_epochs):\n",
    "        for batch in range(w_batchs):\n",
    "            opt_w.zero_grad()\n",
    "            output = model(train_features, istrain=True)\n",
    "            loss_train = F.cross_entropy(output, train_labels)\n",
    "            loss_train.backward()\n",
    "            opt_w.step()\n",
    "        \n",
    "            output = model(train_features)\n",
    "            acc_train = float(accuracy(output, train_labels).data.numpy())*100\n",
    "            model.eval()\n",
    "            output = model(val_features)\n",
    "            acc_val = float(accuracy(output, val_labels).data.numpy())*100\n",
    "            output = model(test_features)\n",
    "            acc_test = float(accuracy(output, test_labels).data.numpy())*100\n",
    "            print(\"epoch %d(%d W), tr: %.2f, va: %.2f, ts:%.2f\" %(epoch, batch, acc_train, acc_val, acc_test))\n",
    "            score_list.append([0, epoch, batch, acc_train, acc_val, acc_test])\n",
    "        \n",
    "        for batch in range(a_batchs):\n",
    "            opt_a.zero_grad()\n",
    "            output = model(train_features, istrain=True)\n",
    "            loss_train = F.cross_entropy(output, train_labels)\n",
    "            loss_train.backward()\n",
    "            opt_a.step()\n",
    "            output = model(train_features)\n",
    "            acc_train = float(accuracy(output, train_labels).data.numpy())*100\n",
    "            model.eval()\n",
    "            output = model(val_features)\n",
    "            acc_val = float(accuracy(output, val_labels).data.numpy())*100\n",
    "            output = model(test_features)\n",
    "            acc_test = float(accuracy(output, test_labels).data.numpy())*100\n",
    "            print(\"epoch %d(%d A), tr: %.2f, va: %.2f, ts:%.2f\" %(epoch, batch, acc_train, acc_val, acc_test))\n",
    "            score_list.append([1, epoch, batch, acc_train, acc_val, acc_test])\n",
    "            ws_list.append(list(F.softmax(model.ws_weight, dim=1).data.numpy()[0]))\n",
    "            print(list(F.softmax(model.ws_weight, dim=1).data.numpy()[0]))\n",
    "    ws_array = np.array(ws_list)\n",
    "    score_array = np.array(score_list)\n",
    "    max_ts_acc_iter = score_array[:, 4].argmax(axis=0)\n",
    "    max_ts_acc = score_array[max_ts_acc_iter][-1]\n",
    "    max_va_acc_iter = score_array[:, 3].argmax(axis=0)\n",
    "    max_va_acc = score_array[max_va_acc_iter][-1]    \n",
    "    train_time = perf_counter()-t\n",
    "    print(score_array)\n",
    "    print('max test acc criterion %.4f' % max_ts_acc)\n",
    "    print(score_array[max_ts_acc_iter])\n",
    "    print('max val acc criterion %.4f' % max_va_acc)\n",
    "    print(score_array[max_va_acc_iter])\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         model.eval()\n",
    "#         output = model(val_features)\n",
    "#         acc_val = accuracy(output, val_labels)\n",
    "\n",
    "    return model, acc_val, train_time, score_array, ws_array\n",
    "\n",
    "def test_regression(model, test_features, test_labels):\n",
    "    model.eval()\n",
    "    return accuracy(model(test_features), test_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_regression(model,\n",
    "                     train_features, train_labels,\n",
    "                     val_features, val_labels,\n",
    "                     epochs, weight_decay,\n",
    "                     lr, dropout, test_features, test_labels):\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr,\n",
    "                           weight_decay=weight_decay)\n",
    "    t = perf_counter()\n",
    "    score_list = []\n",
    "    ws_list = []\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(train_features, istrain=True)\n",
    "        ws_list.append(list(F.softmax(model.ws_weight, dim=1).data.numpy()[0]))\n",
    "        if epoch %10==0:\n",
    "            print(list(F.softmax(model.ws_weight, dim=1).data.numpy()[0]))\n",
    "        loss_train = F.cross_entropy(output, train_labels)\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        output = model(train_features)\n",
    "        acc_train = float(accuracy(output, train_labels).data.numpy())*100\n",
    "        model.eval()\n",
    "        output = model(val_features)\n",
    "        acc_val = float(accuracy(output, val_labels).data.numpy())*100\n",
    "        output = model(test_features)\n",
    "        acc_test = float(accuracy(output, test_labels).data.numpy())*100\n",
    "        print(\"epoch %d, tr: %.2f, va: %.2f, ts:%.2f\" %(epoch, acc_train, acc_val, acc_test))\n",
    "        score_list.append([epoch, acc_train, acc_val, acc_test])\n",
    "    ws_array = np.array(ws_list)\n",
    "    score_array = np.array(score_list)\n",
    "    max_ts_acc_iter = score_array[:, 3].argmax(axis=0)\n",
    "    max_ts_acc = score_array[max_ts_acc_iter][-1]\n",
    "    max_va_acc_iter = score_array[:, 2].argmax(axis=0)\n",
    "    max_va_acc = score_array[max_va_acc_iter][-1]    \n",
    "    train_time = perf_counter()-t\n",
    "    print('max test acc criterion %.4f' % max_ts_acc)\n",
    "    print(score_array[max_ts_acc_iter])\n",
    "    print('max val acc criterion %.4f' % max_va_acc)\n",
    "    print(score_array[max_va_acc_iter])\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         model.eval()\n",
    "#         output = model(val_features)\n",
    "#         acc_val = accuracy(output, val_labels)\n",
    "\n",
    "    return model, acc_val, train_time, score_array, ws_array\n",
    "\n",
    "def test_regression(model, test_features, test_labels):\n",
    "    model.eval()\n",
    "    return accuracy(model(test_features), test_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj, features, labels, idx_train, idx_val, idx_test = load_citation(args.dataset, args.normalization, args.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "feauters_bak = features.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = feature_bak.clone()\n",
    "feature_list = [features]\n",
    "t = perf_counter()\n",
    "for i in range(degree):\n",
    "    features = torch.spmm(adj, features)\n",
    "    feature_list.append(features)\n",
    "precompute_time = perf_counter()-t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 1, 0, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features == feature_bak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5480, dtype=torch.float64)\n",
      "tensor(0.7140, dtype=torch.float64)\n",
      "tensor(0.4860, dtype=torch.float64)\n",
      "tensor(0.5440, dtype=torch.float64)\n",
      "tensor(0.6980, dtype=torch.float64)\n",
      "tensor(0.7760, dtype=torch.float64)\n",
      "tensor(0.7860, dtype=torch.float64)\n",
      "tensor(0.7720, dtype=torch.float64)\n",
      "tensor(0.7660, dtype=torch.float64)\n",
      "tensor(0.7700, dtype=torch.float64)\n",
      "tensor(0.7660, dtype=torch.float64)\n",
      "tensor(0.7640, dtype=torch.float64)\n",
      "tensor(0.7600, dtype=torch.float64)\n",
      "tensor(0.7640, dtype=torch.float64)\n",
      "tensor(0.7720, dtype=torch.float64)\n",
      "tensor(0.7800, dtype=torch.float64)\n",
      "tensor(0.7840, dtype=torch.float64)\n",
      "tensor(0.7820, dtype=torch.float64)\n",
      "tensor(0.7880, dtype=torch.float64)\n",
      "tensor(0.7880, dtype=torch.float64)\n",
      "tensor(0.7860, dtype=torch.float64)\n",
      "tensor(0.7840, dtype=torch.float64)\n",
      "tensor(0.7780, dtype=torch.float64)\n",
      "tensor(0.7760, dtype=torch.float64)\n",
      "tensor(0.7800, dtype=torch.float64)\n",
      "tensor(0.7840, dtype=torch.float64)\n",
      "tensor(0.7860, dtype=torch.float64)\n",
      "tensor(0.7860, dtype=torch.float64)\n",
      "tensor(0.7860, dtype=torch.float64)\n",
      "tensor(0.7900, dtype=torch.float64)\n",
      "tensor(0.7940, dtype=torch.float64)\n",
      "tensor(0.7940, dtype=torch.float64)\n",
      "tensor(0.7940, dtype=torch.float64)\n",
      "tensor(0.7940, dtype=torch.float64)\n",
      "tensor(0.7940, dtype=torch.float64)\n",
      "tensor(0.7940, dtype=torch.float64)\n",
      "tensor(0.7880, dtype=torch.float64)\n",
      "tensor(0.7940, dtype=torch.float64)\n",
      "tensor(0.7960, dtype=torch.float64)\n",
      "tensor(0.7960, dtype=torch.float64)\n",
      "tensor(0.8000, dtype=torch.float64)\n",
      "tensor(0.7980, dtype=torch.float64)\n",
      "tensor(0.7980, dtype=torch.float64)\n",
      "tensor(0.8000, dtype=torch.float64)\n",
      "tensor(0.8040, dtype=torch.float64)\n",
      "tensor(0.8020, dtype=torch.float64)\n",
      "tensor(0.8000, dtype=torch.float64)\n",
      "tensor(0.8000, dtype=torch.float64)\n",
      "tensor(0.8000, dtype=torch.float64)\n",
      "tensor(0.8020, dtype=torch.float64)\n",
      "tensor(0.8020, dtype=torch.float64)\n",
      "tensor(0.8020, dtype=torch.float64)\n",
      "tensor(0.8020, dtype=torch.float64)\n",
      "tensor(0.8020, dtype=torch.float64)\n",
      "tensor(0.7980, dtype=torch.float64)\n",
      "tensor(0.7980, dtype=torch.float64)\n",
      "tensor(0.8000, dtype=torch.float64)\n",
      "tensor(0.8000, dtype=torch.float64)\n",
      "tensor(0.8000, dtype=torch.float64)\n",
      "tensor(0.7980, dtype=torch.float64)\n",
      "tensor(0.7980, dtype=torch.float64)\n",
      "tensor(0.8000, dtype=torch.float64)\n",
      "tensor(0.8000, dtype=torch.float64)\n",
      "tensor(0.8000, dtype=torch.float64)\n",
      "tensor(0.8000, dtype=torch.float64)\n",
      "tensor(0.8000, dtype=torch.float64)\n",
      "tensor(0.8000, dtype=torch.float64)\n",
      "tensor(0.8000, dtype=torch.float64)\n",
      "tensor(0.8000, dtype=torch.float64)\n",
      "tensor(0.8000, dtype=torch.float64)\n",
      "tensor(0.8000, dtype=torch.float64)\n",
      "tensor(0.8000, dtype=torch.float64)\n",
      "tensor(0.8000, dtype=torch.float64)\n",
      "tensor(0.8000, dtype=torch.float64)\n",
      "tensor(0.7980, dtype=torch.float64)\n",
      "tensor(0.7980, dtype=torch.float64)\n",
      "tensor(0.7980, dtype=torch.float64)\n",
      "tensor(0.7980, dtype=torch.float64)\n",
      "tensor(0.7980, dtype=torch.float64)\n",
      "tensor(0.7980, dtype=torch.float64)\n",
      "tensor(0.7980, dtype=torch.float64)\n",
      "tensor(0.7980, dtype=torch.float64)\n",
      "tensor(0.7980, dtype=torch.float64)\n",
      "tensor(0.7980, dtype=torch.float64)\n",
      "tensor(0.7960, dtype=torch.float64)\n",
      "tensor(0.7980, dtype=torch.float64)\n",
      "tensor(0.7980, dtype=torch.float64)\n",
      "tensor(0.7960, dtype=torch.float64)\n",
      "tensor(0.7960, dtype=torch.float64)\n",
      "tensor(0.7960, dtype=torch.float64)\n",
      "tensor(0.7960, dtype=torch.float64)\n",
      "tensor(0.7980, dtype=torch.float64)\n",
      "tensor(0.7960, dtype=torch.float64)\n",
      "tensor(0.7960, dtype=torch.float64)\n",
      "tensor(0.7960, dtype=torch.float64)\n",
      "tensor(0.7960, dtype=torch.float64)\n",
      "tensor(0.7960, dtype=torch.float64)\n",
      "tensor(0.7960, dtype=torch.float64)\n",
      "tensor(0.7960, dtype=torch.float64)\n",
      "tensor(0.7960, dtype=torch.float64)\n",
      "Validation Accuracy: 0.7960 Test Accuracy: 0.8070\n",
      "Pre-compute time: 0.0293s, train time: 0.1908s, total: 0.2201s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = get_model(args.model, features.size(1), labels.max().item()+1, args.hidden, args.dropout, args.cuda)\n",
    "if args.model == \"SGC\": features, precompute_time = sgc_precompute(features, adj, args.degree)\n",
    "    \n",
    "\n",
    "model, acc_val, train_time = train_regression(model, features[idx_train], labels[idx_train], features[idx_val], labels[idx_val],\n",
    "                 args.epochs, args.weight_decay, args.lr, args.dropout)\n",
    "acc_test = test_regression(model, features[idx_test], labels[idx_test])\n",
    "\n",
    "print(\"Validation Accuracy: {:.4f} Test Accuracy: {:.4f}\".format(acc_val, acc_test))\n",
    "print(\"Pre-compute time: {:.4f}s, train time: {:.4f}s, total: {:.4f}s\".format(precompute_time, train_time, precompute_time+train_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
