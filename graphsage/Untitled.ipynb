{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preload import load_data\n",
    "from model import *\n",
    "# from edge import *\n",
    "from utils import *\n",
    "from sampler import *\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "\n",
    "root_path = os.getcwd() + '/'\n",
    "\n",
    "dataset = 'reddit'\n",
    "batch_size = 256\n",
    "node_iters = 20\n",
    "emb_size = 128\n",
    "node_early_stop = 20\n",
    "node_least_iter = 100\n",
    "num_neigh0=5\n",
    "num_neigh1=5\n",
    "is_cuda = False\n",
    "if dataset=='pubmed' or dataset=='reddit':\n",
    "    batch_size=128\n",
    "    num_neigh0 = 25\n",
    "    num_neigh1 = 10\n",
    "    node_least_iter = 80\n",
    "\n",
    "eva_size = 16\n",
    "\n",
    "model_name = 'model_save/' + dataset + '.pkl'\n",
    "\n",
    "eva_iter = 4\n",
    "patience = 5\n",
    "\n",
    "from preload import load_data, load_reddit_data\n",
    "\n",
    "adj, features, labels, train_index, val_index, test_index = load_reddit_data(cuda=False)\n",
    "\n",
    "s = SamplerReddit(adj)\n",
    "\n",
    "sampler = s.normal_sample\n",
    "num_nodes = features.shape[0]\n",
    "num_feature = features.shape[1]\n",
    "num_classes = labels.shape[1]\n",
    "feat = nn.Embedding(num_nodes, num_feature)\n",
    "feat.weight = nn.Parameter(torch.FloatTensor(features), requires_grad=False)\n",
    "\n",
    "agg1 = MeanAggregator(feat, sampler, is_softgate=True, cuda=is_cuda)\n",
    "enc1 = Encoder(feat, num_feature, emb_size, agg1, gcn=False, cuda=is_cuda)\n",
    "agg2 = MeanAggregator(\n",
    "    lambda nodes: enc1(nodes).t(), sampler, is_softgate=True, cuda=is_cuda)\n",
    "enc2 = Encoder(lambda nodes: enc1(nodes).t(), enc1.embed_dim, emb_size, agg2,\n",
    "    base_model=enc1, gcn=False, cuda=is_cuda)\n",
    "enc1.num_sample = num_neigh1\n",
    "enc2.num_sample = num_neigh0\n",
    "graphsage = SupervisedGraphSage(num_classes, enc2, drop_out=0.5, cuda=is_cuda)\n",
    "optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, graphsage.parameters()), lr=1.0)\n",
    "\n",
    "def batch_eva(net, x, y, batch_size):\n",
    "    out_list = []\n",
    "    for idx in range(0, len(x),batch_size):\n",
    "        end_idx = min(idx+batch_size,len(x))\n",
    "        batch_nodes = x[idx:end_idx]\n",
    "        output = net.forward(batch_nodes).data.cpu().numpy().argmax(axis=1) \n",
    "        out_list.append(output)\n",
    "    pred = np.concatenate(out_list,axis=0)\n",
    "    acc = accuracy_score(y,pred)\n",
    "    return acc\n",
    "\n",
    "score_list = []\n",
    "times = []\n",
    "patience_count=0\n",
    "max_score=0\n",
    "for batch in range(100000):\n",
    "    batch_nodes = random.sample(list(train_index), batch_size)\n",
    "    start_time = time.time()\n",
    "    optimizer.zero_grad()\n",
    "    label = Variable(torch.LongTensor(labels[batch_nodes].argmax(axis=1)))\n",
    "    if is_cuda:\n",
    "        label = label.cuda()\n",
    "    tr_output, loss = graphsage.loss(\n",
    "        batch_nodes,\n",
    "        label,\n",
    "        is_train=True\n",
    "    )\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    end_time = time.time()\n",
    "    times.append(end_time - start_time)\n",
    "    if batch%eva_iter ==0:\n",
    "        va_nodes = random.sample(list(val_index), eva_size)\n",
    "        tr_acc = batch_eva(graphsage,batch_nodes,labels[batch_nodes].argmax(axis=1),batch_size)\n",
    "        va_acc = batch_eva(graphsage,va_nodes,labels[va_nodes].argmax(axis=1),batch_size)\n",
    "        if va_acc > max_score:\n",
    "            max_score=va_acc\n",
    "            patience_count = 0\n",
    "            torch.save(graphsage.state_dict(), model_name)\n",
    "        else:\n",
    "            patience_count +=1\n",
    "            if patience_count==patience:\n",
    "                print('Early Stop')\n",
    "                break\n",
    "        print('Epoch: %d,' %(batch),\n",
    "          '|Pat: %d/%d' % (patience_count, patience),\n",
    "          '|loss: %.4f' % loss.data.numpy(),\n",
    "          '|tr_acc: %.4f' % tr_acc,\n",
    "          '|va_acc: %.4f' % va_acc)\n",
    "print('*'*20, 'Final Test', '*'*20)\n",
    "graphsage.load_state_dict(torch.load(model_name))  \n",
    "ts_acc = batch_eva(graphsage,test_index,labels[test_index].argmax(axis=1),batch_size)\n",
    "print('Test Acc:%.4f'%ts_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
